{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_example(example):\n",
    "    example_dict = {\n",
    "        \"srno\": example.get(\"srno\", None),\n",
    "        \"nl_command\": example.get(\"nl_command\", None),\n",
    "        \"bash_code\": example.get(\"bash_code\", None),\n",
    "    }\n",
    "    text = f\"[INST] Docstring: {example_dict['nl_command']} [/INST] Code: {example_dict['bash_code']}\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "def extract_code_type1(input_string):\n",
    "    # Define the regex pattern to match text between \\begin{code} and \\end{code}\n",
    "    pattern = r'\\\\begin\\{code\\}(.*?)\\\\end\\{code\\}'\n",
    "    \n",
    "    # Use re.search to find the first occurrence of the pattern\n",
    "    match = re.search(pattern, input_string, re.DOTALL)\n",
    "    \n",
    "    # Check if a match is found and return the captured group\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def run_llama_inference(nl_command):\n",
    "    \n",
    "    API_URL = os.getenv(\"llama_api_url\")\n",
    "    headers = {\n",
    "        \"Accept\" : \"application/json\",\n",
    "        \"Authorization\": os.getenv(\"hf_token\"),\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    def query(payload):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    output = query({\n",
    "        \"inputs\": f\"Bash code to {nl_command}\",\n",
    "        \"parameters\": {\n",
    "            \"temperature\": 0.01,\n",
    "            \"max_new_tokens\": 500\n",
    "        }\n",
    "    })\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "def extract_pairs(input_string):\n",
    "\n",
    "    # Regular expression pattern to extract instruction and code\n",
    "    pattern = r'\\[INST\\] Docstring: (.+?) \\[/INST\\] Code: (.+)'\n",
    "\n",
    "    # Match the pattern\n",
    "    match = re.match(pattern, input_string)\n",
    "\n",
    "    # Extract instruction and code\n",
    "    if match:\n",
    "        nl_command = match.group(1)\n",
    "        actual_code = match.group(2)\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "    return actual_code, nl_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"AnishJoshi/nl2bash-custom\", split=\"test\")\n",
    "test_data = test_dataset.map(preprocess_example, remove_columns=[\"srno\", \"nl_command\", \"bash_code\"])\n",
    "\n",
    "# Initialize variables for scores and total number of valid examples\n",
    "total_bleu_score = 0.0\n",
    "total_rouge_score = 0.0\n",
    "total_correct_predictions = 0\n",
    "num_examples = len(test_data)\n",
    "\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in test_data:\n",
    "    try:\n",
    "        # Encapsulate the processing of each example inside a try-except block\n",
    "        actual_code, nl_command = extract_pairs(example['text'])\n",
    "\n",
    "        # Run inference to get the predicted code\n",
    "        predicted_code = run_llama_inference(nl_command)\n",
    "        \n",
    "        # Extract the code body if necessary\n",
    "        predicted_code = extract_code_type1(predicted_code)\n",
    "\n",
    "        # Calculate BLEU score\n",
    "        bleu_score = sentence_bleu([actual_code.split()], predicted_code.split())\n",
    "        total_bleu_score += bleu_score\n",
    "\n",
    "        # Calculate ROUGE score\n",
    "        rouge_scores = rouge.get_scores(predicted_code, actual_code)\n",
    "        total_rouge_score += rouge_scores[0]['rouge-1']['f']\n",
    "\n",
    "        # Calculate binary accuracy\n",
    "        if predicted_code.strip() == actual_code.strip():\n",
    "            total_correct_predictions += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example: {str(e)}\")\n",
    "        # Skip example if any step fails\n",
    "        num_examples -= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "average_bleu_score = total_bleu_score / num_examples\n",
    "average_rouge_score = total_rouge_score / num_examples\n",
    "binary_accuracy = total_correct_predictions / num_examples\n",
    "\n",
    "# Print the average scores\n",
    "print(f\"Average BLEU-1 score: {average_bleu_score:.2f}\")\n",
    "print(f\"Average ROUGE-1 score: {average_rouge_score:.2f}\")\n",
    "print(f\"Binary accuracy: {binary_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
